---
title: "Linear regression++"
params:
  answers: true
mainfont: Arial
fontsize: 12pt
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 1
    toc_float: true
    theme: paper
  pdf_document:
    toc: true
    toc_depth: 1
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

In this practical, you will learn how to handle many variables with regression by using variable selection techniques, shrinkage techniques, and how to tune hyper-parameters for these techniques. This practical has been derived from chapter 6 of ISLR. And is designed to build upon previous techniques reviewed in the Basic Tabs, including [Dplyr](<https://dplyr.tidyverse.org/>) & [For Loops](<https://r4ds.had.co.nz/iteration.html>). 

One of the packages we are going to use is `glmnet`. For this, you will probably need to `install.packages("glmnet")` before running the `library()` functions.

```{r packages, warning = FALSE, message = FALSE}
library(ISLR)
library(glmnet)
library(tidyverse)
```

```{r seed, include = FALSE}
set.seed(45)
```


# Best subset selection
Our goal for today is to use the `Hitters` dataset from the `ISLR` package to predict `Salary`.

---

1. __Prepare a dataframe `baseball` from the `Hitters` dataset where you remove the baseball players for which the `Salary` is missing. How many baseball players are left?__

_Hint_: Use the `dplyr` function `filter()` to specify which players you want in the new data frame.

---

```{r naomit}
baseball <- filter(Hitters, Salary != 'N/A')
baseball

```


---

2. a) __Create `baseball_train` (50%), `baseball_valid` (30%), and `baseball_test` (20%) datasets.__

_Hint_: In addition to once again using the `dplyr` function `filter()` to specify which players you want in the new data frame, consider how you can split the amount of players into three groups of these specified sizes.

---


```{r split}
split <- c(rep("train",132),rep("valid",79),rep("test",52))
baseball <- baseball %>% mutate(split=sample(split))
baseball_train <- baseball %>% filter(split=="train")
baseball_valid <- baseball %>% filter(split=="valid")
baseball_test  <- baseball %>% filter(split=="test")

```

---

2. b) __Using your knowledge of `ggplot` from the last practical, plot the salary information of the train, validate and test groups using `geom_histogram()` or `geom_density()`__

```{r hist}
ggplot() + 
  geom_histogram(data = baseball_train, mapping = aes(x = Salary), alpha = 0.3, colour = "Blue") + 
  geom_histogram(data = baseball_valid, mapping = aes(x = Salary), alpha = 0.3, colour = "Red") + 
  geom_histogram(data = baseball_test,  mapping = aes(x = Salary), alpha = 0.3, colour = "Green")  

 

 

 

ggplot() + 
  geom_density(data = baseball_train, mapping = aes(x = Salary), alpha = 0.3, colour = "Blue") + 
  geom_density(data = baseball_valid, mapping = aes(x = Salary), alpha = 0.3, colour = "Red") + 
  geom_density(data = baseball_test,  mapping = aes(x = Salary), alpha = 0.3, colour = "Green") 

```


---

3. __Create a function called `lm_mse()` with as inputs (1) a formula, (2) a training dataset, and (3) a test dataset which outputs the mse on the test dataset for predictions from a linear model.__

---

Start like this:

```{r lmmse1, eval = FALSE}
lm_mse <- function(formula, train_data, valid_data) {
  y_name <- as.character(formula)[2]
  y_true <- valid_data[[y_name]]
 
  # this one is my own code
  mymodel <- lm(formula, train_data)
  mean((y_true-predict(mymodel, newdata=valid_data))^2)
}

```

---

4. __Try out your function with the formula `Salary ~ Hits + Runs`, using `baseball_train` and `baseball_valid`.__

---

```{r lmmse3}
lm_mse(Salary~Hits + Runs, baseball_train, baseball_valid)

```

We have pre-programmed a function for you to generate as a character vector _all_ formulas with a set number of `p` variables. You can load the function into your environment by _sourcing_ the `.R` file it is written in:

```{r src}
source("generate_formulas.R")
```

You can use it like so:

```{r use}
generate_formulas(p = 2, x_vars = c("x1", "x2", "x3", "x4"), y_var = "y")
```

---

5. __Create a character vector of all predictor variables from the `Hitters` dataset. `colnames()` may be of help. Note that `Salary` is not a predictor variable.__

---

```{r enum}
x.vars <- colnames(Hitters)
x.vars <- x.vars[x.vars!="Salary"]
```


---

6. __Using the function `generate_formulas()`, generate all formulas with as outcome `Salary` and 3 predictors from the `Hitters` data. Assign this to a variable called `formulas`. There should be `r choose(19, 3)` elements in this vector.__

---


```{r frmls}
formulas <- generate_formulas(3, x.vars, "Salary")
length(formulas)
```

---

7. __Use a `for loop` to find the best set of 3 predictors in the `Hitters` dataset based on MSE. Use the `baseball_train` and `baseball_valid` datasets.__

When creating the `for` loop, use the function `as.formula()` from the stats package to loop over all the formulas. Before then selecting the best formula with the best MSE using the function `which.min()`.

---

```{r forloop}
mses_3 <- NULL

 

 

 

for (i in 1:length(formulas)) {
  mses_new <- lm_mse(as.formula(formulas[i]), baseball_train, baseball_valid)
  mses_3 <- c(mses_3, mses_new)
}
```

---

8. __Do the same for 1, 2 and 4 predictors. Now select the best model with 1, 2, 3, or 4 predictors in terms of its out-of-sample MSE__

---

```{r forloops, cache = TRUE, results = "hold"}
mses_1 <- NULL
formulas <- generate_formulas(1, x.vars, "Salary")

 

 

 

for (i in 1:length(formulas)) {
  mses_new <- lm_mse(as.formula(formulas[i]), baseball_train, baseball_valid)
  mses_1 <- c(mses_1, mses_new)
}

 

 

 

mses_2 <- NULL
formulas <- generate_formulas(2, x.vars, "Salary")

 

 

 

for (i in 1:length(formulas)) {
  mses_new <- lm_mse(as.formula(formulas[i]), baseball_train, baseball_valid)
  mses_2 <- c(mses_2, mses_new)
}

 

 

 

mses_4 <- NULL
formulas <- generate_formulas(4, x.vars, "Salary")

 

 

 

for (i in 1:length(formulas)) {
  mses_new <- lm_mse(as.formula(formulas[i]), baseball_train, baseball_valid)
  mses_4 <- c(mses_4, mses_new)
}

 

 

 


min(mses_1)
min(mses_2)
min(mses_3)
min(mses_4)

 

 

 

formulas[which.min(mses_4)]
 
```

---

9. __Calculate the test MSE for this model. Then, create a plot comparing predicted values (mapped to x position) versus observed values (mapped to y position) of `baseball_test`.__

---


```{r msefinal}

lm_best <- lm(as.formula(formulas[which.min(mses_4)]), baseball_train)
mse <- function(y_true, y_pred) mean((y_true - y_pred)^2)
mse(baseball_test$Salary, predict(lm_best, newdata = baseball_test))

 

 

 

lm_best_predict <- tibble(y_true = baseball_test$Salary, y_predict = predict(lm_best, newdata = baseball_test))

 

 

 

ggplot() + 
  geom_point(data = lm_best_predict, mapping = aes(x = y_predict, y = y_true)) +
  geom_abline(intercept=0, slope=1) + 
  theme_minimal()

```

Through enumerating all possibilities, we have selected the best subset of at most 4 non-interacting predictors for the prediction of baseball salaries. This method works well for few predictors, but the computational cost of enumeration increases quickly to the point where it is infeasible to enumerate all combinations of variables:

```{r increase, echo = FALSE}
P <- 1:30
data.frame(npred = P, 
           nmod  = rowSums(outer(P, P, choose))) %>% 
  ggplot(aes(x = npred, y = nmod)) +
  geom_line(col = "dark blue", size = 1) +
  theme_minimal() +
  labs(x = "Number of predictors", y = "Number of linear submodels")
```


# Regularisation with glmnet

`glmnet` is a package that implements efficient (quick!) algorithms for LASSO and ridge regression, among other things.

---

10. __Skim through the help file of `glmnet`. We are going to perform a linear regression with normal (gaussian) error terms. What format should our data be in?__

```{r}
?glmnet
```

---

Again, we will try to predict baseball salary, this time using all the available variables and using the LASSO penalty to perform subset selection. For this, we first need to generate an input matrix.

---

11. __First generate the input matrix using (a variation on) the following code. Remember that the "." in a formula means "all available variables". Make sure to check that this `x_train` looks like what you would expect.__

---

```{r modelmat1, eval = FALSE}
x_train <- model.matrix(Salary ~ ., data = baseball_train %>% select(-split))
```

```{r modelmat}

```
The `model.matrix()` function takes a dataset and a formula and outputs the predictor matrix where the categorical variables have been correctly transformed into dummy variables, and it adds an intercept. It is used internally by the `lm()` function as well!

---

12. __Using `glmnet()`, perform a LASSO regression with the generated `x_train` as the predictor matrix and `Salary` as the response variable. Set the `lambda` parameter of the penalty to 15. NB: Remove the intercept column from the `x_matrix` -- `glmnet` adds an intercept internally.__

---

```{r lasso}
glmnet(x = x_train, y = baseball_train$Salary, family = c("gaussian"), nlambda = 15, alpha = 1)
```

---

13. __The coefficients for the variables are in the `beta` element of the list generated by the `glmnet()` function. Which variables have been selected? You may use the `coef()` function.__

---

```{r sel}

```


---

14. __Create a predicted versus observed plot for the model you generated with the `baseball_valid` data. Use the `predict()` function for this! What is the MSE on the validation set?__

---

```{r predobs}

```

# Tuning lambda

Like many methods of analysis, regularised regression has a _tuning parameter_. In the previous section, we've set this parameter to 15. The `lambda` parameter changes the strength of the shrinkage in `glmnet()`. Changing the tuning parameter will change the predictions, and thus the MSE. In this section, we will select the tuning parameter based on out-of-sample MSE.


---

15. __Fit a LASSO regression model on the same data as before, but now do not enter a specific `lambda` value. What is different about the object that is generated? Hint: use the `coef()` and `plot()` methods on the resulting object.__

---

```{r lambdas}

```

For deciding which value of lambda to choose, we could work similarly to what we have don in the best subset selection section before. However, the `glmnet` package includes another method for this task: cross validation.

---

16. __Use the `cv.glmnet` function to determine the `lambda` value for which the out-of-sample MSE is lowest using 15-fold cross validation. As your dataset, you may use the training and validation sets bound together with bind_rows(). What is the best lambda value?__

**Remember** to remove column 21 in your dataset (the mutated column from Question 2 using `[ , -21]`), as this is not a variable within the Baseball Data. And to call the specific data `lambda.min` from the result of using `cv.glmnet`.

---

```{r cv}

```

---

17. __Try out the plot() method on this object. What do you see? What does this tell you about the bias-variance tradeoff?__

---


```{r cvplot}

```

---

18. __Use the `predict()` method directly on the object you just created to predict new salaries for the baseball players in the `baseball_test` dataset using the best lambda value you just created (hint: you need to use the `s` argument, look at `?predict.cv.glmnet` for help). Create another predicted-observed scatter plot.__

---

```{r laspred}

```

It should be noted, that for all these previous exercises they can also be completed using the **Ridge Method** which is not covered in much depth during this practical session. To learn more about this method please refer back Section 6.2 in the An Introduction to Statistical Learning Textbook. 


# Exercise: method comparison

---

19. __Create a bar plot comparing the test set (baseball_test) MSE of (a) linear regression with all variables, (b) the best subset selection regression model we created, (c) LASSO with lambda set to 50, and (d) LASSO with cross-validated lambda. As training dataset, use the rows in both the `baseball_train` and `baseball_valid`__

---

```{r barplot}

```
